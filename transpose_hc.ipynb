{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LibInsight Transposition Utility\n",
    "\n",
    "This notebook provides a means to convert hourly gate or head count data for upload into LibInsight by 'flattening' a multi-column table into two columns. \n",
    "\n",
    "It is recommended that the source file be moved or copied to the same directory as this notebook. \n",
    "\n",
    "Two means of checking the correctness of the output have been included:\n",
    "\n",
    "1. The total count of expected rows in the output is calculated as the product of the number of rows in the source data multiplied by the number of columns in the source data. Because of the way in which the table is being flattened, the output of this process should have exactly that many rows.\n",
    "2. Because every data point measures the same thing, it is also possible to compare the sum of the all counts within the source data against the sum of counts following transposition. Again, these should be the same.\n",
    "\n",
    "Note that Pandas can import and export Excel files as well as CSV. If that is preferable, reading Excel and exporting CSV can be accomplished with only minor changes to the code.\n",
    "\n",
    "**NOTE:** If confidence in this process is high, it is possible to run all of the cells with one command. Before doing so, please make sure to edit the source and output file names as needed.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide the name of the source file\n",
    "\n",
    "Edit the next line as needed. It is recommended to remove spaces and special characters from the source file name before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_file = 'fadl.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read/Open the source file and print the first five rows\n",
    "\n",
    "__NOTE:__ To read Excel files instead, simply change the *pd.read_csv* to *pd.read_excel*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8:30</th>\n",
       "      <th>9:30</th>\n",
       "      <th>10:30</th>\n",
       "      <th>11:30</th>\n",
       "      <th>12:30</th>\n",
       "      <th>13:30</th>\n",
       "      <th>14:30</th>\n",
       "      <th>15:30</th>\n",
       "      <th>16:30</th>\n",
       "      <th>17:30</th>\n",
       "      <th>18:30</th>\n",
       "      <th>19:30</th>\n",
       "      <th>20:30</th>\n",
       "      <th>21:30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1/17/2011</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/18/2011</th>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/19/2011</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/20/2011</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/21/2011</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           8:30  9:30  10:30  11:30  12:30  13:30  14:30  15:30  16:30  17:30  \\\n",
       "1/17/2011     0     0      0      0      0      0      0      0      0      0   \n",
       "1/18/2011    10    19     39     50      0     40     35     36     28     30   \n",
       "1/19/2011     7    12     48     64     52     53     52     57      0      0   \n",
       "1/20/2011     9    14     37     55      0     55     62     43     47     27   \n",
       "1/21/2011     3    16      0     65     69     44      0     47      0     31   \n",
       "\n",
       "           18:30  19:30  20:30  21:30  \n",
       "1/17/2011      0      0      0      0  \n",
       "1/18/2011     27      0     15      6  \n",
       "1/19/2011     22     18     19     15  \n",
       "1/20/2011     22     22     14     10  \n",
       "1/21/2011      0      0      0      0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(source_file, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the number of expected rows in the transposed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of rows in the output:  30324\n"
     ]
    }
   ],
   "source": [
    "expected_rows = len(df.index)*len(df.columns)\n",
    "print(\"Expected number of rows in the output: \", str(expected_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the sum total of all the data in the source table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum total of source data:  696893\n"
     ]
    }
   ],
   "source": [
    "source_sum = df.sum().sum()\n",
    "print(\"Sum total of source data: \", str(source_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose the columns into rows\n",
    "\n",
    "Transposition is quickly done using the Pandas 'stack' method, which creates a form of Pivot Table. The resulting data frame itself can't be exported because we still need to add a column with the correct date/time format.\n",
    "\n",
    "Following stacking, double check the row count. The number of rows in the stacked data frame should be equal to the expected number of rows in the output. We could also get the sum total here, too, but for now that second check is left to the end of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far so good. Expecting 30324 rows and transposed data frame has 30324 rows.\n"
     ]
    }
   ],
   "source": [
    "stacked = df.stack()\n",
    "\n",
    "stacked_rows = len(stacked)\n",
    "if stacked_rows == expected_rows:\n",
    "    print(\"So far so good. Expecting\", str(expected_rows), \"rows and transposed data frame has\", str(stacked_rows), \"rows.\")\n",
    "else:\n",
    "    print(\"Error. Expecting\", str(expected_rows), \"rows and transposed data frame has\", str(stacked_rows), \"rows. Please check.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the date/time column\n",
    "\n",
    "The \"stacked\" data frame has two indices - one for the date, a second for the time. These need to be \"combined\" into a single column. The approach taken here, which is simple though perhaps not most efficient, is to create a new, empty data frame to hold the final output. Then, for each row in the \"stacked\" data frame, append concatenated date/time info and count info as a new row into the output data frame.\n",
    "\n",
    "Note that this step may take some time.\n",
    "\n",
    "As a quick check, view the first five rows of the output. Ignore the leftmost \"column\" of zeros or integers. This is an index, which is required by Pandas data frames. The index will be excluded from the final CSV output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/17/2011:8:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/17/2011:9:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/17/2011:10:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/17/2011:11:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/17/2011:12:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date_time count\n",
       "0   1/17/2011:8:30     0\n",
       "0   1/17/2011:9:30     0\n",
       "0  1/17/2011:10:30     0\n",
       "0  1/17/2011:11:30     0\n",
       "0  1/17/2011:12:30     0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['date_time', 'count']\n",
    "output = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range(len(stacked)):\n",
    "    tocat = stacked.index[i]\n",
    "    dt = tocat[0]+\":\"+tocat[1]\n",
    "    v = stacked.iloc[i]\n",
    "    tmpdf = pd.DataFrame([[dt, v]], columns=cols)\n",
    "    output = output.append(tmpdf)\n",
    "    \n",
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for errors\n",
    "\n",
    "Before outputting the results to CSV, check to verify that the data frame has the correct number of expected rows AND the same sum total as the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First check successful. Expecting 30324 rows and final data frame has 30324 rows.\n"
     ]
    }
   ],
   "source": [
    "output_rows = len(output)\n",
    "\n",
    "if output_rows == expected_rows:\n",
    "    print(\"First check successful. Expecting\", str(expected_rows), \"rows and final data frame has\", str(output_rows), \"rows.\")\n",
    "else:\n",
    "    print(\"Error. Expecting\", str(expected_rows), \" rows and final data frame has\", str(output_rows), \"rows. Please check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second check successful. Expecting sum total of 696893 and final total is 696893 .\n"
     ]
    }
   ],
   "source": [
    "output_sum = output.sum()[1]\n",
    "\n",
    "if output_sum == source_sum:\n",
    "    print(\"Second check successful. Expecting sum total of\", str(source_sum), \"and final total is\", str(output_sum), \".\")\n",
    "else:\n",
    "    print(\"Error. Expecting sum total of\", str(source_sum), \"and final total is\", str(output_sum), \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write results to file\n",
    "\n",
    "If both checks are successful, the final results can be written out to a CSV file. Provide a different name for the output file as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = 'fadl_data.csv'\n",
    "output.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
